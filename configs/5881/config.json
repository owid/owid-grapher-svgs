{
  "id": 5881,
  "map": {
    "columnSlug": "180076"
  },
  "data": {
    "availableEntities": [
      "Theseus",
      "Self Organizing System",
      "Perceptron Mark I",
      "Samuel Neural Checkers",
      "ADALINE",
      "Neocognitron",
      "Back-propagation",
      "NetTalk",
      "NetTalk (dictionary)",
      "NetTalk (transcription)",
      "Motion-Driven 3D Feature Tracking",
      "Innervator",
      "ALVINN",
      "Zip CNN",
      "SRN-Encoded Grammatical Structures",
      "TD-Gammon",
      "Fuzzy NN",
      "IBM-5",
      "GroupLens",
      "Iterative Bootstrapping WSD",
      "Random Decision Forests",
      "Support Vector Machines",
      "System 11",
      "HMM Word Alignment",
      "SVM for face detection",
      "Bidirectional RNN",
      "LSTM",
      "Sparse coding model for V1 receptive fields",
      "Social and content-based classification",
      "LeNet-5",
      "LSTM with forget gates",
      "IBM Model 4",
      "Perceptron for Large Margin Classification",
      "FrameNet role labeling",
      "Decision tree (classification)",
      "Thumbs Up?",
      "Maximum Entropy Models for machine translation",
      "NPLM",
      "Phrase-based translation",
      "Unsupervised Scale-Invariant Learning",
      "CNN Best Practices",
      "Max-Margin Markov Networks",
      "SACHS",
      "Hiero",
      "ConvNet similarity metric",
      "Histograms of Oriented Gradients",
      "BiLSTM for Speech",
      "DrLIM",
      "CTC-Trained LSTM",
      "DImensionality Reduction",
      "Deep Belief Nets",
      "Sparse Energy-Based Model",
      "Restricted Bolzmann machines",
      "Regularized SVD for Collaborative Filtering",
      "Deep Multitask NLP Network",
      "BigChaos 2008",
      "Semantic Hashing",
      "GPU DBNs",
      "BellKor 2008",
      "BellKor 2009",
      "BigChaos OptiBlend",
      "MatrixFac for Recommenders",
      "BellKor 2007",
      "6-layer MLP (MNIST)",
      "Word Representations",
      "ReLU (NORB)",
      "KN5 LM + RNN 400/10 (WSJ)",
      "RNN 500/10 + RT09 LM (NIST RT05)",
      "YouTube Video Recommendation System",
      "RNN-SpeedUp",
      "Domain Adaptation",
      "NLP from scratch",
      "MCDNN (MNIST)",
      "Dropout (ImageNet)",
      "Dropout (MNIST)",
      "Dropout (TIMIT)",
      "Unsupervised High-level Feature Learner",
      "AlexNet",
      "Mitosis",
      "Word2Vec (large)",
      "Word2Vec (small)",
      "TransE",
      "Image generation",
      "GloVe (32B)",
      "GloVe (6B)",
      "GANs",
      "SPPNet",
      "Multiresolution CNN",
      "SmooCT",
      "RNNsearch-50*",
      "VGG16",
      "VGG19",
      "Seq2Seq LSTM",
      "DSN",
      "Deeply-supervised nets",
      "LRCN",
      "MSRA (C, PReLU)",
      "DQN-2015",
      "GoogLeNet / InceptionV1",
      "BPE",
      "Inception v3",
      "DeepSpeech2 (English)",
      "ResNet-152 (ImageNet)",
      "AlphaGo Lee",
      "Spatiotemporal fusion ConvNet",
      "R-FCN",
      "GNMT",
      "Xception",
      "PolyNet",
      "Fisher Kernel GMM",
      "DeepStack",
      "MoE",
      "Transformer",
      "JFT",
      "RetinaNet-R101",
      "AlphaGo Zero",
      "CapsNet (MNIST)",
      "PNASNet-5",
      "AlphaZero",
      "AmoebaNet-A (F=448)",
      "IMPALA",
      "YOLOv3",
      "ResNeXt-101 32x48d",
      "GPT",
      "Big-Little Net",
      "BigGAN-deep 512x512",
      "BERT-Large",
      "GPipe (Amoeba)",
      "GPipe (Transformer)",
      "Decoupled weight decay regularization",
      "GPT-2 (1542M)",
      "ProxylessNAS",
      "KataGo",
      "MnasNet-A1 + SSDLite",
      "MnasNet-A3",
      "FixRes ResNeXt-101 WSL",
      "RoBERTa Large",
      "ObjectNet",
      "Megatron-BERT",
      "Megatron-LM (8.3B)",
      "ALBERT",
      "T5-11B",
      "T5-3B",
      "Noisy Student (L2)",
      "MuZero",
      "OpenAI Five",
      "OpenAI Five Rerun",
      "Meena",
      "ALBERT-xxlarge",
      "Turing-NLG",
      "GPT-3 175B (davinci)",
      "GShard (dense)",
      "ViT-H/14",
      "wave2vec 2.0 LARGE",
      "SimCLRv2",
      "KEPLER",
      "CPM-Large",
      "CLIP (ResNet-50)",
      "CLIP (ViT L/14@336px)",
      "DALL-E",
      "BigSSL",
      "Meta Pseudo Labels",
      "M6-T",
      "ProtT5-XXL",
      "CogView",
      "Transformer local-attention (NesT-B)",
      "ViT-G/14",
      "DeBERTa",
      "ALIGN",
      "Denoising Diffusion Probabilistic Models (LSUN Bedroom)",
      "EfficientNetV2",
      "ERNIE 3.0",
      "Codex",
      "HuBERT",
      "XLMR-XXL",
      "FLAN",
      "HyperClova",
      "Megatron-Turing NLG 530B",
      "Yuan 1.0",
      "Florence",
      "Gopher (280B)",
      "GLaM",
      "XGLM",
      "ERNIE 3.0 Titan",
      "ERNIE-ViLG",
      "data2vec (language)",
      "data2vec (speech)",
      "data2vec (vision)",
      "InstructGPT",
      "RETRO-7B",
      "GPT-NeoX-20B",
      "LaMDA",
      "DeepNet",
      "Statement Curriculum Learning",
      "Chinchilla",
      "PaLM (540B)",
      "DALL·E 2",
      "Stable Diffusion (LDM-KL-8-G)",
      "Sparse all-MLP",
      "Imagen",
      "Parti",
      "Minerva (540B)",
      "NLLB",
      "Whisper",
      "BLOOM",
      "Falcon-40B",
      "PanGu-Σ",
      "PaLM 2",
      "InternLM",
      "Llama 2",
      "Jais",
      "Falcon 180B",
      "SNARC",
      "Genetic algorithm",
      "Sequence-based pattern recognition",
      "Conditional probability machines",
      "Pandemonium (morse)",
      "Pattern recognition and reading by machine",
      "LMS",
      "Heuristic problem solving for AI",
      "MADALINE I",
      "BOXES",
      "GLEE",
      "Graph-based structural reasoning",
      "Naive Bayes",
      "Cognitron",
      "TD(0)",
      "Internal functionality of visual invariants",
      "Kohonen network",
      "Hopfield network",
      "ASE+ACE",
      "Learnability theory of language development",
      "Error Propagation",
      "PDP model for serial order",
      "Optimized Multi-Scale Edge Detection",
      "Q-learning",
      "Time-delay neural networks",
      "Universal approximation via Feedforward Networks",
      "MADALINE III",
      "MLP as Bayesian Approximator",
      "REINFORCE in Stochastic Connectionism",
      "SVD in recommender systems",
      "Gradient Boosting Machine",
      "NEAT in neuroevolution",
      "Tagging via Viterbi Decoding",
      "Statistical Shape Constellations",
      "LDA",
      "Stanley (DARPA Grand Challenge 2)",
      "FAST",
      "Spatial Pyramid Matching",
      "Local Binary Patterns for facial recognition",
      "Greedy layer-wise DNN training",
      "BLSTM for handwriting (1)",
      "Multiscale deformable part model",
      "Denoising Autoencoders",
      "Semi-Supervised Embedding for DL",
      "Boss (DARPA Urban Challenge)",
      "Sparse digit recognition SVM",
      "Deep Boltzmann Machines",
      "Conv-DBN",
      "3D city reconstruction",
      "Stacked Denoising Autoencoders",
      "Feedforward NN",
      "Deconvolutional Network",
      "Mid-level Features",
      "ReLU (LFW)",
      "RBM-tuning",
      "Fisher-Boost",
      "Culturome",
      "Optimized Single-layer Net",
      "Deep rectifier networks",
      "Cross-Lingual POS Tagger",
      "Recursive sentiment autoencoder",
      "Adaptive Subgrad",
      "HOGWILD!",
      "Dropout (CIFAR)",
      "MV-RNN",
      "Context-dependent RNN",
      "LSTM-300units",
      "RNN+LDA+KN5+cache",
      "Bayesian automated hyperparameter tuning",
      "Textual Imager",
      "Maxout Networks",
      "PreTrans-3L-250H",
      "SearchFusion",
      "SemVec",
      "Image Classification with the Fisher Vector: Theory and Practice",
      "RNN+weight noise+dynamic eval",
      "R-CNN (T-net)",
      "Visualizing CNNs",
      "TensorReasoner",
      "DBLSTM",
      "Network in Network",
      "DQN",
      "DOT(S)-RNN",
      "OverFeat",
      "SPN-4+KN5",
      "HyperNEAT",
      "Dropout (2014)",
      "GRUs",
      "Two-stream ConvNets for action recognition",
      "DeepFace",
      "Large regularized LSTM",
      "Fully Convolutional Networks",
      "Cascaded LNet-ANet",
      "NTM",
      "ADAM (CIFAR-10)",
      "DeepLab",
      "CRF-RNN",
      "Constituency-Tree LSTM",
      "genCNN + dyn eval",
      "Fast R-CNN",
      "Deep LSTM for video classification",
      "Trajectory-pooled conv nets",
      "Faster R-CNN",
      "YOLO",
      "BatchNorm",
      "Search-Proven Best LSTM",
      "Listen, Attend and Spell",
      "LSTM-Char-Large",
      "Deep Deterministic Policy Gradients",
      "AlphaGo Fan",
      "Multi-scale Dilated CNN",
      "Netflix Recommender System",
      "ResNet-110 (CIFAR-10)",
      "BPL",
      "Advantage Learning",
      "Variational (untied weights, MC) LSTM (Large)",
      "Convolutional Pose Machines",
      "A3C FF hs",
      "Inception-ResNet-V2",
      "Inceptionv4",
      "SqueezeNet",
      "Symmetric Residual Encoder-Decoder Net",
      "DMN",
      "Wide & Deep",
      "fastText",
      "VD-RHN",
      "Character-enriched word2vec",
      "Named Entity Recognition model",
      "Part-of-sentence tagging model",
      "DenseNet-264",
      "Multi-task Cascaded CNN",
      "WaveNet",
      "Youtube recommendation model",
      "MS-CNN",
      "ResNet-1001",
      "ResNet-200",
      "Stacked hourglass network",
      "TSN",
      "Wide Residual Network",
      "Pointer Sentinel-LSTM (medium)",
      "Zoneout + Variational LSTM (WT2)",
      "Differentiable neural computer",
      "VD-LSTM+REAL Large",
      "NASv3 (CIFAR-10)",
      "Neural Architecture Search with base 8 and shared embeddings",
      "Deeply-recursive ConvNet",
      "ResNeXt-50",
      "RefineNet",
      "Image-to-image cGAN",
      "Elastic weight consolidation",
      "PointNet",
      "GAN-Advancer",
      "Diabetic Retinopathy Detection Net",
      "GCNN-14",
      "YOLOv2",
      "AlphaGo Master",
      "Libratus",
      "DnCNN",
      "Prototypical networks",
      "Mask R-CNN",
      "WGAN-GP",
      "MobileNet",
      "DeepLab (2017)",
      "SRGAN",
      "Inflated 3D ConvNet",
      "PointNet++",
      "EDSR",
      "HRA",
      "DeepLabV3",
      "NoisyNet-Dueling",
      "ShuffleNet v1",
      "AWD-LSTM",
      "NASNet-A",
      "PSPNet",
      "AWD-LSTM - 3-layer LSTM (tied) + continuous cache pointer (WT2)",
      "RetinaNet-R50",
      "OpenAI TI7 DOTA 1v1",
      "EI-REHN-1000D",
      "Cutout-regularized net",
      "NeuMF (Pinterest)",
      "GL-LWGC-AWD-MoS-LSTM + dynamic evaluation (WT2)",
      "SENet (ImageNet)",
      "ISS",
      "LSTM + dynamic eval",
      "AWD-LSTM+WT+Cache+IOG (WT2)",
      "LRSO-GAN",
      "CapsNet (MultiMNIST)",
      "ProgressiveGAN",
      "Fraternal dropout + AWD-LSTM 3-layer (WT2)",
      "AWD-LSTM-MoS + dynamic evaluation (WT2, 2017)",
      "TriNet",
      "PNAS-net",
      "2-layer-LSTM+Deep-Gradient-Compression",
      "Refined Part Pooling",
      "ULM-FiT",
      "ELMo",
      "QRNN",
      "AmoebaNet-A (F=190)",
      "DeepLabV3+",
      "ENAS",
      "Spectrally Normalized GAN",
      "Residual Dense Network",
      "Chinese - English translation",
      "LSTM (2018)",
      "Rotation",
      "4 layer QRNN (h=2500)",
      "LSTM (Hebbian, Cache, MbPA)",
      "Dropout-LSTM+Noise(Bernoulli) (WT2)",
      "aLSTM(depth-2)+RecurrentPolicy (WT2)",
      "Relational Memory Core",
      "MobileNetV2",
      "DARTS",
      "ShuffleNet v2",
      "Population-based DRL",
      "RCAN",
      "AWD-LSTM-MoS+PDR + dynamic evaluation (WT2)",
      "(ensemble): AWD-LSTM-DOC (fin) × 5 (WT2)",
      "ESRGAN",
      "AWD-LSTM-MoS + dynamic evaluation (WT2, 2018)",
      "LSTM+NeuralCache",
      "Transformer (Adaptive Input Embeddings)",
      "TrellisNet",
      "Fine-tuned-AWD-LSTM-DOC(fin)",
      "Multi-cell LSTM",
      "Transformer ELMo",
      "Transformer-XL Large",
      "MT-DNN",
      "Hanabi 4 player",
      "FAIRSEQ Adaptive Inputs",
      "Cross-lingual alignment",
      "True-Regularization+Finetune+Dynamic-Eval",
      "Transformer-XL + RMS dynamic eval",
      "SpecAugment",
      "BERT-Large-CAS (PTB+WT2+WT103)",
      "DANet",
      "ResNeXt-101 Billion-scale",
      "ResNet-50 Billion-scale",
      "AWD-LSTM-DRILL + dynamic evaluation† (WT2)",
      "CPC v2",
      "EfficientNet-L2",
      "DLRM-2020",
      "XLM",
      "XLNet",
      "AMDIM",
      "Transformer-XL Large + Phrase Induction",
      "AWD-LSTM + MoS + Partial Shuffled",
      "Char-CNN-BiLSTM",
      "Walking Minotaur robot",
      "Tensorized Transformer (257M)",
      "BigBiGAN",
      "Pluribus",
      "EN^2AS with performance reward",
      "Mogrifier (d2, MoS2, MC) + dynamic eval",
      "Adaptive Inputs + LayerDrop",
      "AlphaX-1",
      "DistilBERT",
      "BART-large",
      "AlphaStar",
      "Base LM + kNN LM + Continuous Cache",
      "Sandwich Transformer",
      "MoCo",
      "Photo-Geometric Autoencoder",
      "Transformer-XL DeFINE (141M)",
      "StarGAN v2",
      "MMLSTM",
      "Big Transfer (BiT-L)",
      "AlphaFold",
      "Theseus 6/768",
      "Perceiver IO",
      "TaLK Convolution",
      "SimCLR",
      "Feedback Transformer",
      "Temporal Convolutional Attention-based Network(TCAN) (WT2)",
      "TransformerXL + spectrum control",
      "Routing Transformer",
      "Tensor-Transformer(1core)+PN (WT103)",
      "ELECTRA",
      "MetNet",
      "Agent57",
      "CURL",
      "Go-explore",
      "Once for All",
      "NAS+ESS (156M)",
      "Hopfield Networks (2020)",
      "EfficientDet",
      "DeLight",
      "ERNIE-GEN (large)",
      "ViT-Base/32",
      "ViT-Huge/14",
      "AlphaFold2",
      "VQGAN + CLIP",
      "CT-MoS (WT2)",
      "ERNIE-Doc (247M)",
      "top-down frozen classifier",
      "Rational DQN Average",
      "SRU++ Large",
      "Generative BST",
      "Megatron-LM (1T)",
      "PLUG",
      "ConSERT",
      "Adaptive Input Transformer + RD",
      "Zidong Taichu",
      "MEB",
      "PermuteFormer",
      "PLATO-XL",
      "base LM+GNN+kNN",
      "EfficientZero",
      "S4",
      "NÜWA",
      "Player of Games",
      "AlphaCode",
      "Segatron-XL large, M=384 + HCP",
      "Flamingo",
      "UL2",
      "Gato",
      "SimCSE",
      "Tranception",
      "CogVideo",
      "DITTO",
      "MetaLM",
      "AlexaTM 20B",
      "GLM-130B",
      "Make-A-Video",
      "Phenaki",
      "Taiyi-Stable Diffusion",
      "Mogrifier RLSTM (WT2)",
      "AltCLIP",
      "Galactica",
      "AR-LDM",
      "CICERO",
      "ALM 1.0",
      "GPT-3.5 (text-davinci-003)",
      "Hybrid H3-2.7B",
      "Gen-1",
      "Claude",
      "GPT-4",
      "Vicuna-13B",
      "MusicGen",
      "RoboCat",
      "Inflection-1",
      "ERNIE 3.5",
      "Stable Diffusion XL",
      "Claude 2",
      "Swift",
      "Robot Parkour",
      "GPT-4V",
      "Show-1",
      "Ferret (13B)",
      "Gen-2"
    ]
  },
  "slug": "artificial-intelligence-number-training-datapoints",
  "type": "ScatterPlot",
  "title": "Datapoints used to train notable artificial intelligence systems",
  "xAxis": {
    "label": "Publication date"
  },
  "yAxis": {
    "label": "Training datapoints",
    "scaleType": "log",
    "canChangeScaleType": true
  },
  "$schema": "https://files.ourworldindata.org/schemas/grapher-schema.003.json",
  "version": 180,
  "subtitle": "Each domain has a specific data point unit; for example, for vision it is images, for language it is words, and for games it is timesteps. This means systems can only be compared directly within the same domain.",
  "originUrl": "http://ourworldindata.org/artificial-intelligence",
  "colorScale": {
    "baseColorScheme": "owid-distinct",
    "binningStrategy": "manual",
    "legendDescription": "Task domain",
    "customCategoryLabels": {
      "games": "Games",
      "speech": "Speech",
      "vision": "Vision",
      "No data": "Other",
      "driving": "Driving",
      "general": "General",
      "language": "Language"
    }
  },
  "dimensions": [
    {
      "property": "y",
      "variableId": 815784
    },
    {
      "property": "color",
      "variableId": 815780
    }
  ],
  "entityType": "system",
  "isPublished": true,
  "entityTypePlural": "systems",
  "hideConnectedScatterLines": false,
  "hideAnnotationFieldsInTitle": {
    "time": true,
    "entity": true,
    "changeInPrefix": true
  }
}