{
  "id": 5566,
  "map": {
    "variableId": 180076
  },
  "data": {
    "availableEntities": [
      "Theseus",
      "SNARC",
      "Georgetown experiment",
      "Self Organizing System",
      "Perceptron Mark I",
      "Pandemonium (morse)",
      "Samuel Neural Checkers",
      "Pattern recognition and reading by machine",
      "ADALINE",
      "LMS",
      "MADALINE I",
      "STUDENT",
      "ELIZA",
      "GLEE",
      "BOXES",
      "Punish/Reward",
      "Naive Bayes",
      "Cognitron",
      "SAM",
      "TD(0)",
      "Neocognitron",
      "Kohonen network",
      "Hopfield network",
      "ASE+ACE",
      "Racter",
      "Back-propagation",
      "NetTalk",
      "Q-learning",
      "Innervator",
      "Time-delay neural networks",
      "ALVINN",
      "Zip CNN",
      "MADALINE III",
      "TD-Gammon",
      "Fuzzy NN",
      "IBM-5",
      "GroupLens",
      "Random Decision Forests",
      "Support Vector Machines",
      "System 11",
      "HMM Word Alignment",
      "BRNN",
      "LSTM",
      "LeNet-5",
      "LSTM with forget gates",
      "IBM Model 4",
      "Decision tree (classification)",
      "Thumbs Up?",
      "LDA",
      "NPLM",
      "Phrase-based translation",
      "Unsupervised Scale-Invariant Learning",
      "CNN Best Practices",
      "SACHS",
      "Hiero",
      "BiLSTM for Speech",
      "Stanley (DARPA Grand Challenge 2)",
      "FAST",
      "DrLIM",
      "CTC-Trained LSTM",
      "DImensionality Reduction",
      "Deep Belief Nets",
      "Restricted Bolzmann machines",
      "Denoising Autoencoders",
      "Boss (DARPA Urban Challenge)",
      "BigChaos 2008",
      "Semantic Hashing",
      "Deep Boltzmann Machines",
      "6-layer MLP (MNIST)",
      "Feedforward NN",
      "Word Representations",
      "Deconvolutional Network",
      "ReLU (NORB)",
      "ReLU (LFW)",
      "RNN 500/10 + RT09 LM (NIST RT05)",
      "KN5 LM + RNN 400/10 (WSJ)",
      "Domain Adaptation",
      "NLP from scratch",
      "MCDNN (MNIST)",
      "Dropout (MNIST)",
      "Dropout (TIMIT)",
      "Dropout (CIFAR)",
      "Dropout (ImageNet)",
      "MV-RNN",
      "AlexNet",
      "DQN",
      "Maxout Networks ",
      "PreTrans-3L-250H",
      "Image Classification with the Fisher Vector: Theory and Practice",
      "Mitosis",
      "Word2Vec (large)",
      "Word2Vec (small)",
      "R-CNN (T-net)",
      "Visualizing CNNs",
      "TransE",
      "DBLSTM",
      "Network in Network",
      "Image generation",
      "GloVe (6B)",
      "GloVe (32B)",
      "GRUs",
      "GANs",
      "SPPNet",
      "Multiresolution CNN",
      "SmooCT",
      "RNNsearch-50*",
      "VGG16",
      "VGG19",
      "Seq2Seq LSTM",
      "LRCN",
      "NTM",
      "ADAM (CIFAR-10)",
      "DeepLab",
      "MSRA (C, PReLU)",
      "DQN-2015",
      "Constituency-Tree LSTM",
      "Fast R-CNN",
      "DSN",
      "Faster R-CNN",
      "GoogLeNet / InceptionV1",
      "YOLO",
      "BatchNorm",
      "BPE",
      "AlphaGo Fan",
      "Inception v3",
      "DeepSpeech2",
      "ResNet-152 (ImageNet)",
      "ResNet-110 (CIFAR-10)",
      "BPL",
      "Advantage Learning",
      "AlphaGo Lee",
      "A3C FF hs",
      "Inceptionv4",
      "Inception-ResNet-V2",
      "SqueezeNet",
      "DMN",
      "R-FCN",
      "Part-of-sentence tagging model",
      "Named Entity Recognition model",
      "DenseNet-264",
      "Stacked hourglass network",
      "MS-CNN",
      "Wide Residual Network",
      "GNMT",
      "Xception",
      "NASv3 (CIFAR-10)",
      "ResNeXt-50",
      "RefineNet",
      "PointNet",
      "YOLOv2",
      "Libratus",
      "AlphaGo Master",
      "Mask R-CNN",
      "MobileNet",
      "PointNet++",
      "Transformer",
      "DeepLabV3",
      "NoisyNet-Dueling",
      "ShuffleNet v1",
      "NASNet-A",
      "JFT",
      "RetinaNet-R50",
      "RetinaNet-R101",
      "OpenAI TI7 DOTA 1v1",
      "NeuMF (Pinterest)",
      "SENet (ImageNet)",
      "AlphaGo Zero",
      "CapsNet (MNIST)",
      "CapsNet (MultiMNIST)",
      "PNASNet-5",
      "PNAS-net",
      "AlphaZero",
      "Refined Part Pooling",
      "ULM-FiT",
      "ELMo",
      "AmoebaNet-A (F=190)",
      "AmoebaNet-A (F=448)",
      "DeepLabV3+",
      "Rotation",
      "YOLOv3",
      "GPT",
      "MobileNetV2",
      "ShuffleNet v2",
      "ESRGAN",
      "BigGAN-deep 512x512",
      "BERT-Large",
      "Decoupled weight decay regularization",
      "GPT-2",
      "ResNet-50 Billion-scale",
      "EfficientNet-L2",
      "MnasNet-A1 + SSDLite",
      "MnasNet-A3",
      "XLNet",
      "RoBERTa",
      "ObjectNet",
      "ALBERT",
      "T5-3B",
      "T5-11B",
      "BART-large",
      "AlphaStar",
      "MoCo",
      "MuZero",
      "OpenAI Five",
      "OpenAI Five Rerun",
      "AlphaFold",
      "ALBERT-xxlarge",
      "SimCLR",
      "CURL",
      "GPT-3 175B (davinci)",
      "ViT-H/14",
      "wave2vec 2.0 LARGE",
      "AlphaFold2",
      "CLIP (ViT L/14@336px)",
      "DALL-E",
      "CLIP (ResNet-50)",
      "Rational DQN Average",
      "Meta Pseudo Labels",
      "M6-T",
      "Generative BST",
      "PLUG",
      "Transformer local-attention (NesT-B)",
      "Denoising Diffusion Probabilistic Models (LSUN Bedroom)",
      "Codex",
      "HuBERT",
      "XLMR-XXL",
      "FLAN",
      "MEB",
      "NÜWA",
      "Player of Games",
      "XGLM",
      "data2vec (vision)",
      "data2vec (speech)",
      "data2vec (language)",
      "InstructGPT",
      "AlphaCode",
      "GPT-NeoX-20B",
      "LaMDA",
      "Chinchilla",
      "PaLM (540B)",
      "DALL·E 2",
      "Stable Diffusion (LDM-KL-8-G)",
      "Sparse all-MLP",
      "Flamingo",
      "UL2",
      "Gato",
      "MetaLM",
      "Parti",
      "Minerva (540B)",
      "NLLB",
      "AlexaTM 20B",
      "Whisper",
      "Make-A-Video",
      "GPT-4"
    ]
  },
  "logo": "owid",
  "note": "Computation is estimated based on published results in the AI literature and comes with some uncertainty. The authors expect the estimates to be correct within a factor of 2.",
  "slug": "artificial-intelligence-training-computation",
  "type": "ScatterPlot",
  "title": "Computation used to train notable artificial intelligence systems",
  "xAxis": {
    "label": "Publication date"
  },
  "yAxis": {
    "scaleType": "log",
    "canChangeScaleType": true
  },
  "details": {
    "general": {
      "flop": {
        "id": 6,
        "term": "flop",
        "title": "Floating-point operation",
        "content": "A floating-point operation (FLOP) is a type of computer operation. One FLOP is equivalent to one addition, subtraction, multiplication, or division of two decimal numbers.",
        "category": "general"
      }
    }
  },
  "version": 134,
  "subtitle": "Computation is measured in total petaFLOP, which is 10¹⁵ [floating-point operations](#dod:flop).",
  "originUrl": "https://ourworldindata.org/artificial-intelligence",
  "colorScale": {
    "baseColorScheme": "owid-distinct",
    "binningStrategy": "manual",
    "legendDescription": "Task domain",
    "customCategoryLabels": {
      "games": "Games",
      "speech": "Speech",
      "vision": "Vision",
      "No data": "Other",
      "driving": "Driving",
      "general": "General",
      "language": "Language"
    }
  },
  "dimensions": [
    {
      "display": {
        "shortUnit": "",
        "includeInTable": true
      },
      "property": "y",
      "variableId": 312259
    },
    {
      "property": "color",
      "variableId": 312256
    }
  ],
  "entityType": "system",
  "isPublished": true,
  "entityTypePlural": "systems",
  "hideConnectedScatterLines": false,
  "hideAnnotationFieldsInTitle": {
    "time": true,
    "entity": true,
    "changeInPrefix": true
  }
}