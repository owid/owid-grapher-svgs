{
  "id": 8150,
  "note": "The regression lines show a sharp rise in data used to train AI systems since 2010, driven by the success of deep learning methods that leverage neural networks and massive datasets.",
  "slug": "exponential-growth-of-datapoints-used-to-train-notable-ai-systems",
  "title": "Exponential growth of datapoints used to train notable AI systems",
  "xAxis": {
    "label": "Publication date"
  },
  "yAxis": {
    "label": "Training datapoints",
    "scaleType": "log",
    "canChangeScaleType": true
  },
  "$schema": "https://files.ourworldindata.org/schemas/grapher-schema.009.json",
  "version": 208,
  "subtitle": "Each domain has a specific data point unit; for example, for vision it is images, for language it is words, and for games it is timesteps. This means systems can only be compared directly within the same domain.",
  "originUrl": "/artificial-intelligence",
  "chartTypes": [
    "ScatterPlot"
  ],
  "colorScale": {
    "baseColorScheme": "owid-distinct",
    "binningStrategy": "manual",
    "legendDescription": "",
    "customCategoryColors": {
      "Other": "#6e7581",
      "Maximum data": "#d73c50"
    },
    "customCategoryLabels": {
      "games": "Games",
      "speech": "Speech",
      "vision": "Vision",
      "No data": "Other",
      "driving": "Driving",
      "general": "General",
      "language": "Language"
    },
    "customNumericColorsActive": true
  },
  "dimensions": [
    {
      "property": "y",
      "variableId": 1015508
    }
  ],
  "entityType": "system",
  "isPublished": true,
  "entityTypePlural": "systems",
  "excludedEntityNames": [
    "Americas (UNWTO)",
    "Other (UNWTO)",
    "Maximum compute",
    "Maximum parameters"
  ],
  "selectedEntityNames": [
    "Theseus",
    "Perceptron Mark I",
    "AlexNet",
    "GPT-1",
    "GPT-4",
    "Transformer (2017)",
    "1.2x/year between 1950–2010",
    "2.7x/year between 2010–2025"
  ],
  "selectedEntityColors": {
    "GPT-1": "#6d3e91",
    "GPT-4": "#6d3e91",
    "AlexNet": "#6d3e91",
    "Theseus": "#9a5129",
    "1.0x/year": "#6d3e91",
    "1.3x/year": "#9a5129",
    "2.3x/year": "#38aaba",
    "2.4x/year": "#970046",
    "2.7x/year": "#6d3e91",
    "LLaMA-65B": "#6d3e91",
    "Transformer": "#6d3e91",
    "GPT-2 (1.5B)": "#d73c50",
    "Back-propagation": "#9a5129",
    "Transformer 2017": "#6d3e91",
    "Perceptron Mark I": "#9a5129",
    "Transformer (2017)": "#6d3e91",
    "1.0x/year between 2010–2018": "#6d3e91",
    "1.1x/year between 2010–2017": "#6d3e91",
    "1.2x/year between 1950–2010": "#9a5129",
    "1.3x/year between 1950–2010": "#9a5129",
    "2.4x/year between 2010–2025": "#6d3e91",
    "2.5x/year between 2010–2025": "#6d3e91",
    "2.6x/year between 2010–2025": "#6d3e91",
    "2.7x/year between 2010–2025": "#6d3e91",
    "2.7x/year between 2018–2025": "#18470f",
    "2.8x/year between 2010–2025": "#6d3e91",
    "3.3x/year between 2017–2025": "#18470f"
  },
  "hideAnnotationFieldsInTitle": {
    "time": true,
    "entity": true,
    "changeInPrefix": true
  }
}