{
  "id": 6929,
  "map": {
    "columnSlug": "736553"
  },
  "note": "Performance on these benchmarks should not be compared directly as they use different performance metrics and test different skills.",
  "slug": "ai-performance-coding-math-knowledge-tests",
  "title": "Top performing AI systems in coding, math, and language-based knowledge tests",
  "yAxis": {
    "max": 100,
    "min": 0,
    "facetDomain": "independent"
  },
  "$schema": "https://files.ourworldindata.org/schemas/grapher-schema.006.json",
  "version": 48,
  "subtitle": "Coding performance is measured with the  [APPS benchmark](#dod:ai-APPS); math performance with the [MATH benchmark](#dod:ai-MATH); and language-based knowledge tests with the  [MMLU benchmark](#dod:ai-MMLU).",
  "originUrl": "https://ourworldindata.org/artificial-intelligence",
  "dimensions": [
    {
      "property": "y",
      "variableId": 852091
    },
    {
      "property": "y",
      "variableId": 852092
    },
    {
      "display": {
        "name": "Math",
        "includeInTable": true
      },
      "property": "y",
      "variableId": 852089
    },
    {
      "display": {
        "name": "Knowledge tests",
        "includeInTable": true
      },
      "property": "y",
      "variableId": 852090
    }
  ],
  "entityType": "subject",
  "isPublished": true,
  "hideTimeline": true,
  "addCountryMode": "disabled",
  "comparisonLines": [
    {
      "label": "Math and knowledge tests: approximate score of expert human",
      "yEquals": "90"
    },
    {
      "label": "Math: average score of 5 university students",
      "yEquals": "68"
    },
    {
      "label": "Knowledge tests: average score of non-expert humans",
      "yEquals": "35"
    }
  ],
  "entityTypePlural": "subjects",
  "hideRelativeToggle": false,
  "selectedEntityNames": [
    "State of the art"
  ],
  "facettingLabelByYVariables": "skill or knowledge area",
  "hideAnnotationFieldsInTitle": {
    "time": true,
    "entity": true
  }
}