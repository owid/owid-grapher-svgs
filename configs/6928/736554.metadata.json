{
  "id": 736554,
  "name": "Top-1 accuracy - state of the art",
  "unit": "%",
  "description": "The top-1 accuracy measure is used to assess how frequently a model's absolute top prediction matches the correct answer from a given set of options.  Here's an example to illustrate what this benchmark tests:\n\nImagine an image classification model that is presented with an image of an animal. The model assigns probabilities to each potential label and generates its highest-confidence prediction. For instance, when analyzing an image, the model might predict \"Cat\" as the most probable label. To evaluate the model's accuracy using the top-1 measure, researchers compare this prediction with the correct label. If the model's top prediction matches the correct label (e.g., if the actual animal in the image is indeed a cat), then the model's prediction is considered correct according to the top-1 accuracy metric. On the other hand, if the model's top prediction does not match the correct label (e.g., if the image shows a dog, but the model predicts a cat), then the model's prediction is considered incorrect based on the top-1 accuracy measure. To calculate the top-1 accuracy, researchers analyze the model's performance on a large dataset where the correct labels are known. They determine the percentage of examples in the dataset where the model's highest-confidence prediction matches the actual label.\n\nThis measure provides a focused evaluation of the model's ability to make accurate predictions by considering only its absolute top guess.\n",
  "createdAt": "2023-07-03T14:54:56.000Z",
  "updatedAt": "2024-07-08T16:38:15.000Z",
  "coverage": "",
  "timespan": "",
  "datasetId": 6103,
  "shortUnit": "%",
  "columnOrder": 0,
  "shortName": "papers_with_code_imagenet_top1_state_of_the_art",
  "catalogPath": "grapher/artificial_intelligence/2023-06-14/papers_with_code_benchmarks_state_of_the_art/papers_with_code_benchmarks_state_of_the_art#papers_with_code_imagenet_top1_state_of_the_art",
  "type": "float",
  "datasetName": "Performance on Coding, Math, Language, Image Classification and Atari tasks - only state of the art(Papers With Code, 2023)",
  "datasetVersion": "2023-06-14",
  "nonRedistributable": false,
  "display": {
    "name": "Top-1 accuracy",
    "unit": "%",
    "zeroDay": "2019-01-01",
    "shortUnit": "%",
    "yearIsDay": true,
    "numDecimalPlaces": 1
  },
  "schemaVersion": 1,
  "presentation": {
    "topicTagsLinks": [],
    "faqs": []
  },
  "descriptionKey": [],
  "source": {
    "id": 29583,
    "name": "Papers With Code (2023)",
    "dataPublishedBy": "Papers With Code",
    "dataPublisherSource": "",
    "link": "https://paperswithcode.com/",
    "retrievedDate": "2023-06-14",
    "additionalInfo": "\nThe goal of Papers With Code website is to compile a comprehensive collection of ML papers, code implementations, datasets, methods, and evaluation tables, all made freely available.\n\nThe comparisons to human performance are very approximate and based on small samples of people â€” they are only meant to give a rough comparison. You can read more details in the papers that describe the benchmarks:\n\n-Hendrycks et al (2021) Measuring Massive Multitask Language Understanding (MMLU) (page 3): https://arxiv.org/pdf/2009.03300.pdf\n\n-Hendrycks et al (2021) Measuring Mathematical Problem Solving With the MATH Dataset (page 5): https://arxiv.org/pdf/2103.03874v2.pdf\n"
  },
  "dimensions": {
    "years": {
      "values": [
        {
          "id": -2222
        },
        {
          "id": -1580
        },
        {
          "id": -1118
        },
        {
          "id": -1043
        },
        {
          "id": -862
        },
        {
          "id": -529
        },
        {
          "id": -395
        },
        {
          "id": -330
        },
        {
          "id": -244
        },
        {
          "id": 164
        },
        {
          "id": 314
        },
        {
          "id": 357
        },
        {
          "id": 371
        },
        {
          "id": 442
        },
        {
          "id": 447
        },
        {
          "id": 889
        },
        {
          "id": 890
        },
        {
          "id": 1164
        },
        {
          "id": 1219
        },
        {
          "id": 1504
        }
      ]
    },
    "entities": {
      "values": [
        {
          "id": 366954,
          "name": "State of the Art",
          "code": null
        }
      ]
    }
  },
  "origins": []
}