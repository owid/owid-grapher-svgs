{
  "id": 736555,
  "name": "Top-5 accuracy - state of the art",
  "unit": "%",
  "description": "The top-5 accuracy measure is used to assess how frequently a model's top five predictions include the correct answer from a list of 1000 options. Here's an example to illustrate what this benchmark tests:\n\nWhen an image classification model is presented with an image of an animal, it will assign probabilities to each possible label. Based on these probabilities, the model generates its top five predictions out of a total of 1000 animal labels. For instance, the model might output the following predictions as its top five guesses: * \t\tCat * \t\tDog * \t\tElephant * \t\tLion * \t\tTiger\n\nSuppose the correct label for the image is \"dog.\" If \"dog\" appears among the model's top five predictions, then the model's prediction is considered correct according to the top-5 accuracy metric.\n\nOn the other hand, if the correct label is \"giraffe\" and \"giraffe\" is not included in the model's top five predictions, then the model's prediction would be considered incorrect based on the top-5 accuracy measure.\n\nTo calculate the top-5 accuracy, researchers evaluate the model's performance on a large dataset with known labels. They compute the percentage of examples in the dataset where the correct label is present within the model's top five predictions out of the 1000 possible options. This measure provides a broader perspective on the model's performance by considering whether the correct answer is among its top guesses, even if it's not the model's absolute top prediction.\n",
  "createdAt": "2023-07-03T14:54:57.000Z",
  "updatedAt": "2024-07-08T16:38:15.000Z",
  "coverage": "",
  "timespan": "",
  "datasetId": 6103,
  "shortUnit": "%",
  "columnOrder": 0,
  "shortName": "papers_with_code_imagenet_top5_state_of_the_art",
  "catalogPath": "grapher/artificial_intelligence/2023-06-14/papers_with_code_benchmarks_state_of_the_art/papers_with_code_benchmarks_state_of_the_art#papers_with_code_imagenet_top5_state_of_the_art",
  "type": "float",
  "datasetName": "Performance on Coding, Math, Language, Image Classification and Atari tasks - only state of the art(Papers With Code, 2023)",
  "datasetVersion": "2023-06-14",
  "nonRedistributable": false,
  "display": {
    "name": "Top-5 accuracy",
    "unit": "%",
    "zeroDay": "2019-01-01",
    "shortUnit": "%",
    "yearIsDay": true,
    "numDecimalPlaces": 1
  },
  "schemaVersion": 1,
  "presentation": {
    "topicTagsLinks": [],
    "faqs": []
  },
  "descriptionKey": [],
  "source": {
    "id": 29583,
    "name": "Papers With Code (2023)",
    "dataPublishedBy": "Papers With Code",
    "dataPublisherSource": "",
    "link": "https://paperswithcode.com/",
    "retrievedDate": "2023-06-14",
    "additionalInfo": "\nThe goal of Papers With Code website is to compile a comprehensive collection of ML papers, code implementations, datasets, methods, and evaluation tables, all made freely available.\n\nThe comparisons to human performance are very approximate and based on small samples of people â€” they are only meant to give a rough comparison. You can read more details in the papers that describe the benchmarks:\n\n-Hendrycks et al (2021) Measuring Massive Multitask Language Understanding (MMLU) (page 3): https://arxiv.org/pdf/2009.03300.pdf\n\n-Hendrycks et al (2021) Measuring Mathematical Problem Solving With the MATH Dataset (page 5): https://arxiv.org/pdf/2103.03874v2.pdf\n"
  },
  "dimensions": {
    "years": {
      "values": [
        {
          "id": -2222
        },
        {
          "id": -1580
        },
        {
          "id": -1420
        },
        {
          "id": -1118
        },
        {
          "id": -1043
        },
        {
          "id": -1021
        },
        {
          "id": -776
        },
        {
          "id": -529
        },
        {
          "id": -330
        },
        {
          "id": -244
        },
        {
          "id": 164
        },
        {
          "id": 314
        },
        {
          "id": 357
        },
        {
          "id": 371
        },
        {
          "id": 447
        },
        {
          "id": 1056
        }
      ]
    },
    "entities": {
      "values": [
        {
          "id": 366954,
          "name": "State of the Art",
          "code": null
        }
      ]
    }
  },
  "origins": []
}